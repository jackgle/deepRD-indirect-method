{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632d1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datapath_ribench = '../../../v1_1/data/RIbench/'\n",
    "outpath = './ribench_sample_v2/'\n",
    "test_set_meta = pd.read_csv(datapath_ribench+'/BMTestSets_meta.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5629d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for dirpath, dirnames, filenames in os.walk(datapath_ribench+'/Data/'):\n",
    "    for filename in filenames:\n",
    "        files.append(os.path.join(dirpath, filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a747612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i for i in files if i.split('/')[-2] not in ['CRP', 'LDH']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0b5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sub = np.random.choice(len(files), 1000)\n",
    "files_sub = [files[i] for i in idx_sub]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741fe12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath)\n",
    "    \n",
    "def get_y(file):\n",
    "    fileid = int(file.split('/')[-1].split('_')[0])\n",
    "    target = (\n",
    "        test_set_meta[test_set_meta.Index==fileid].GT_LRL.values[0],\n",
    "        test_set_meta[test_set_meta.Index==fileid].GT_URL.values[0]\n",
    "    )\n",
    "    return np.array(target)\n",
    "\n",
    "samples = []\n",
    "targets = []\n",
    "for c,i in enumerate(files_sub):\n",
    "    if c%100==0:\n",
    "        print(c)\n",
    "    sample = pd.read_csv(i, header=None).values.squeeze()\n",
    "    samples.append(sample)\n",
    "    targets.append(get_y(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2196c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath)\n",
    "with open(outpath+'/x.pkl', 'wb') as f:\n",
    "    pickle.dump(samples, f)\n",
    "with open(outpath+'/y.pkl', 'wb') as f:\n",
    "    pickle.dump(targets, f)\n",
    "with open(outpath+'/files.pkl', 'wb') as f:\n",
    "    pickle.dump(files_sub, f)\n",
    "pd.DataFrame(files_sub, columns=['file'], index=None).to_csv(outpath+'/files.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ebd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
